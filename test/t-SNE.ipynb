{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchvision.transforms import PILToTensor,ToTensor,Normalize,Resize\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch\n",
    "import motmetrics\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "from torchreid.utils import FeatureExtractor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchreid\n",
    "from data_utils.data_load import simple_dataset\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import  seaborn as sns\n",
    "from sacred import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/gauthier/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='osnet_x1_0',\n",
    "    num_classes=20,\n",
    "    pretrained=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OSNet(\n",
       "  (conv1): ConvLayer(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): Sequential(\n",
       "    (0): OSBlock(\n",
       "      (conv1): Conv1x1(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2a): LightConv3x3(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2b): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2c): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): ChannelGate(\n",
       "        (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate_activation): Sigmoid()\n",
       "      )\n",
       "      (conv3): Conv1x1Linear(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Conv1x1Linear(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): OSBlock(\n",
       "      (conv1): Conv1x1(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2a): LightConv3x3(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2b): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2c): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): LightConv3x3(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): ChannelGate(\n",
       "        (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate_activation): Sigmoid()\n",
       "      )\n",
       "      (conv3): Conv1x1Linear(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1x1(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): OSBlock(\n",
       "      (conv1): Conv1x1(\n",
       "        (conv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2a): LightConv3x3(\n",
       "        (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2b): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2c): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): ChannelGate(\n",
       "        (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate_activation): Sigmoid()\n",
       "      )\n",
       "      (conv3): Conv1x1Linear(\n",
       "        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Conv1x1Linear(\n",
       "        (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): OSBlock(\n",
       "      (conv1): Conv1x1(\n",
       "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2a): LightConv3x3(\n",
       "        (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2b): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2c): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): LightConv3x3(\n",
       "          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): ChannelGate(\n",
       "        (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate_activation): Sigmoid()\n",
       "      )\n",
       "      (conv3): Conv1x1Linear(\n",
       "        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1x1(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): OSBlock(\n",
       "      (conv1): Conv1x1(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2a): LightConv3x3(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2b): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2c): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): ChannelGate(\n",
       "        (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate_activation): Sigmoid()\n",
       "      )\n",
       "      (conv3): Conv1x1Linear(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (downsample): Conv1x1Linear(\n",
       "        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): OSBlock(\n",
       "      (conv1): Conv1x1(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2a): LightConv3x3(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2b): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2c): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Sequential(\n",
       "        (0): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): LightConv3x3(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gate): ChannelGate(\n",
       "        (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate_activation): Sigmoid()\n",
       "      )\n",
       "      (conv3): Conv1x1Linear(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Conv1x1(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=500, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model.classifier= nn.Linear(in_features=model.classifier.in_features, out_features=500)\n",
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Made this notebook with the help of https://www.learnopencv.com/t-sne-for-feature-visualization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##to run you will have to run gen_crops with your path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "seed = 10\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mot = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##change this to your path\n",
    "dataset_dir = '/media/data/gauthier/mot_cropped/'+data_mot+'/'\n",
    "all_crops = os.listdir(dataset_dir)\n",
    "tuple_list = []\n",
    "##tuple = [data,label]\n",
    "for crop in all_crops:\n",
    "    tuple_list += [(dataset_dir+crop,int(crop.split('_')[0]))]\n",
    "\n",
    "len(tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex = Experiment('tsne',interactive=True)\n",
    "#ex.add_config('/home/gauthier/reid/res50-mot17-batch_hard/sacred_config.yaml')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import Resize, Compose, ToPILImage, ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "class ResNet(models.ResNet):\n",
    "    def __init__(self, block, layers, output_dim):\n",
    "        super(ResNet, self).__init__(block, layers)\n",
    "        \n",
    "        self.name = \"ResNet\"\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d((8,4), stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, 1024)\n",
    "        self.bn_fc = nn.BatchNorm1d(1024)\n",
    "        self.relu_fc = nn.ReLU(inplace=True)\n",
    "        self.fc_out = nn.Linear(1024, output_dim)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        self.fc_compare = nn.Linear(output_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.bn_fc(x)\n",
    "        x = self.relu_fc(x)\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def load_pretrained_dict(self, state_dict):\n",
    "        \"\"\"Load the pretrained weights and ignore the ones where size does not match\"\"\"\n",
    "        pretrained_state_dict = {k: v for k,v in state_dict.items() for kk,vv in self.state_dict().items() if k==kk and v.size() == vv.size()}\n",
    "        updated_state_dict = self.state_dict()\n",
    "        updated_state_dict.update(pretrained_state_dict)\n",
    "        self.load_state_dict(updated_state_dict)\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_pretrained_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "weights = '/home/gauthier/reid/res50-mot17-batch_hard/ResNet_iter_25245.pth'\n",
    "\n",
    "cnn= resnet50(pretrained=True, output_dim=128)\n",
    "cnn.load_state_dict(torch.load(weights))\n",
    "cnn.eval()\n",
    "cnn =cnn.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn = FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "   model_path='../model_saves/cnn_triplet.pth.tar',#'../model_saves/cnn_softmax.pth.tar'\n",
    "    device='cuda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = simple_dataset(tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=5, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.Resize((256, 128)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "             std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    " \n",
    "labels =[]\n",
    "outputs =[]\n",
    "images= []\n",
    "\n",
    "for i,batch in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "        images_path = batch[0]\n",
    "        lab_batch = [int(b) for b in batch[1] ]\n",
    "        labels += lab_batch\n",
    "\n",
    "        images += images_path\n",
    "        images_pil = [Image.open(img_path) for img_path in images_path]\n",
    "\n",
    "\n",
    "        inputs = torch.stack([transform(img_pil) for img_pil in images_pil])\n",
    "\n",
    "        output = cnn(inputs.to('cuda'))\n",
    "\n",
    "\n",
    "\n",
    "        current_outputs = output.cpu().numpy()\n",
    "        outputs.append(current_outputs)\n",
    "    #features = np.concatenate((outputs, current_outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.stack(outputs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reshape(-1, features.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2).fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_to_01_range(x):\n",
    "\n",
    "    # compute the distribution range\n",
    "\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    "    # move the distribution so that it starts from zero\n",
    "\n",
    "    # by extracting the minimal value from all its values\n",
    "\n",
    "    starts_from_zero = x - np.min(x)\n",
    "\n",
    " \n",
    "\n",
    "    # make the distribution fit [0; 1] by dividing by its range\n",
    "\n",
    "    return starts_from_zero / value_range\n",
    "\n",
    "\n",
    "\n",
    "tx = tsne[:, 0]\n",
    "ty = tsne[:, 1]\n",
    "\n",
    " \n",
    "\n",
    "tx = scale_to_01_range(tx)\n",
    "ty = scale_to_01_range(ty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_np = np.array(tuple_list)\n",
    "num_classes = np.unique(tuple_np[:,1])\n",
    "num_classes = np.asarray(num_classes,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    " \n",
    "\n",
    "# for every class, we'll add a scatter plot separately\n",
    "colors_per_class = { label : sns.color_palette(\"hls\", num_classes.shape[0])[label] for label in num_classes }\n",
    "for label in colors_per_class:\n",
    "\n",
    "    # find the samples of the current class in the data\n",
    "    \n",
    "    indices = [i for i, l in enumerate(labels) if l == label]\n",
    "    # extract the coordinates of the points of this class only\n",
    "\n",
    "    current_tx = np.take(tx, indices)\n",
    "\n",
    "    current_ty = np.take(ty, indices)\n",
    "    # convert the class color to matplotlib format\n",
    "    color = np.array(colors_per_class[label], dtype=np.float)\n",
    " \n",
    "    # add a scatter plot with the corresponding color and label\n",
    "    ax.scatter(current_tx, current_ty, color=color, label=label)\n",
    " \n",
    "ax.legend(loc='best')\n",
    "# finally, show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, max_image_size):\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    scale = max(1, image_width / max_image_size, image_height / max_image_size)\n",
    "    image_width = int(image_width / scale)\n",
    "    image_height = int(image_height / scale)\n",
    "\n",
    "    image = cv2.resize(image, (image_width, image_height))\n",
    "    return image\n",
    "\n",
    "def draw_rectangle_by_class(image, label):\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # get the color corresponding to image class\n",
    "    color = colors_per_class[label]\n",
    "    image = cv2.rectangle(image, (0, 0), (image_width - 1, image_height - 1), color=color, thickness=5)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size =2000\n",
    "max_image_size =100\n",
    "offset = max_image_size // 2\n",
    "\n",
    "image_centers_area_size = plot_size - 2 * offset\n",
    "\n",
    "\n",
    "def compute_plot_coordinates(image, x, y, image_centers_area_size, offset):\n",
    "\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    " \n",
    "\n",
    "    # compute the image center coordinates on the plot\n",
    "\n",
    "    center_x = int(image_centers_area_size * x) + offset\n",
    " \n",
    "    # in matplotlib, the y axis is directed upward\n",
    "    # to have the same here, we need to mirror the y coordinate\n",
    "    center_y = int(image_centers_area_size * (1 - y)) + offset\n",
    " \n",
    "    # knowing the image center,\n",
    "    # compute the coordinates of the top left and bottom right corner\n",
    "    tl_x = center_x - int(image_width / 2)\n",
    "    tl_y = center_y - int(image_height / 2)\n",
    "    br_x = tl_x + image_width\n",
    "    br_y = tl_y + image_height\n",
    " \n",
    "    return tl_x, tl_y, br_x, br_y\n",
    " \n",
    "# we'll put the image centers in the central area of the plot\n",
    "# and use offsets to make sure the images fit the plot\n",
    " \n",
    "# init the plot as white canvas\n",
    "tsne_plot = 255 * np.ones((plot_size, plot_size, 3), np.uint8)\n",
    " \n",
    "# now we'll put a small copy of every image to its corresponding T-SNE coordinate\n",
    "for image_path, label, x, y in zip(images, labels, tx, ty):\n",
    "        \n",
    "    image = cv2.imread(image_path)\n",
    " \n",
    "    # scale the image to put it to the plot\n",
    "    image = scale_image(image, max_image_size)\n",
    " \n",
    "    # draw a rectangle with a color corresponding to the image class\n",
    "    image = draw_rectangle_by_class(image, label)\n",
    " \n",
    "    # compute the coordinates of the image on the scaled plot visualization\n",
    "    tl_x, tl_y, br_x, br_y = compute_plot_coordinates(image, x, y, image_centers_area_size, offset)\n",
    "\n",
    "    # put the image to its t-SNE coordinates using numpy sub-array indices\n",
    "    tsne_plot[tl_y:br_y, tl_x:br_x, :] = image\n",
    "    cv2.putText(tsne_plot,str(label), (tl_x,tl_y), 0, 2, 255)\n",
    "\n",
    "cv2.imwrite('t_sne.png', tsne_plot)\n",
    "#imshow will crashs the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import torch\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/gauthier/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet152', pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0].shape)\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "otp = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otp = torch.reshape(otp,(49,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "import math\n",
    "class Conv1dSame(nn.Module):\n",
    "    \"\"\"Represents the \"Same\" padding functionality from Tensorflow.\n",
    "    NOTE: Only work correctly when dilation == 1, groups == 1 !!!\n",
    "    https://github.com/pytorch/pytorch/issues/3867\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1):\n",
    "        super().__init__()\n",
    "        self.cut_last_element = (kernel_size % 2 == 0 and stride == 1 and dilation % 2 == 1)\n",
    "        self.padding = math.ceil((1 - stride + dilation * (kernel_size-1))/2)\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=self.padding, stride=stride, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cut_last_element:\n",
    "            return self.conv(x)[:, :, :-1]\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "        \n",
    "class Conv1dPaddingSame(nn.Module):\n",
    "    '''pytorch version of padding=='same'\n",
    "    ============== ATTENTION ================\n",
    "    Only work when dilation == 1, groups == 1\n",
    "    =========================================\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(Conv1dPaddingSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.weight = nn.Parameter(torch.rand((out_channels, \n",
    "                                                 in_channels, kernel_size)))\n",
    "        # nn.Conv1d default set bias=True，so create this param\n",
    "        self.bias = nn.Parameter(torch.rand(out_channels))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_channels, length = x.shape\n",
    "        if length % self.stride == 0:\n",
    "            out_length = length // self.stride\n",
    "        else:\n",
    "            out_length = length // self.stride + 1\n",
    "\n",
    "        pad = math.ceil((out_length * self.stride + \n",
    "                         self.kernel_size - length - self.stride) / 2)\n",
    "        out = F.conv1d(input=x, \n",
    "                       weight = self.weight,\n",
    "                       stride = self.stride, \n",
    "                       bias = self.bias,\n",
    "                       padding=pad)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SpatialAttention(torch.nn.Module):\n",
    "    def __init__(self,is_train ):\n",
    "        super(SpatialAttention, self).__init__()        \n",
    "        resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        self.conv_features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        for param in self.conv_features.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.conv1d = Conv1dPaddingSame(49,1,1,1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.last_layer = nn.Linear(in_features=2*2048,out_features=512)\n",
    "        self.train_layer = nn.Linear(in_features=512,out_features=1)\n",
    "        self.is_train = is_train\n",
    "    def forward(self, old_feature, new_feature):\n",
    "        \n",
    "        \n",
    "        new_conv = self.conv_features(new_feature)\n",
    "        old_conv = self.conv_features(old_feature)\n",
    "        \n",
    "        new_conv = new_conv.permute(0,2,3,1)\n",
    "        new_conv = torch.reshape(new_conv,(new_conv.shape[0],49,2048))\n",
    "\n",
    "        old_conv = old_conv.permute(0,2,3,1)\n",
    "        old_conv = torch.reshape(old_conv,(old_conv.shape[0],49,2048))\n",
    "        \n",
    "        \n",
    "        \n",
    "        norm_old_conv = f.normalize(old_conv,dim=0,p=-1)\n",
    "        norm_new_conv = f.normalize(new_conv,dim=0,p=-1)\n",
    "        norm_new_conv_t = new_conv.permute(0,2,1)\n",
    "        \n",
    "        new_match = torch.bmm(norm_old_conv,norm_new_conv_t)\n",
    "        \n",
    "\n",
    "        old_match = new_match.permute(0,2,1)\n",
    "        \n",
    "        new_conv1d = self.conv1d(new_match)\n",
    "        old_conv1d = self.conv1d(old_match)\n",
    "            \n",
    "        \n",
    "        new_att = torch.reshape(new_conv1d,(new_conv1d.shape[0],49))\n",
    "        old_att = torch.reshape(new_conv1d,(new_conv1d.shape[0],49))\n",
    "        \n",
    "        new_att = self.softmax(new_att)\n",
    "        old_att = self.softmax(old_att)\n",
    "        \n",
    "        new_att = torch.reshape(new_conv1d,(new_conv1d.shape[0],49,1))\n",
    "        old_att = torch.reshape(new_conv1d,(new_conv1d.shape[0],49,1))\n",
    "\n",
    "        #new_conv_atted = torch.bmm(new_conv,new_att)\n",
    "        #old_conv_atted = torch.bmm(old_conv,old_att)\n",
    "        new_conv_atted = new_conv * new_att\n",
    "        old_conv_atted = old_conv * old_att\n",
    "\n",
    "        new_conv_atted_sum = torch.sum(new_conv_atted, dim=1)\n",
    "        old_conv_atted_sum = torch.sum(old_conv_atted, dim=1)\n",
    "        \n",
    "        catted = torch.cat([new_conv_atted_sum,old_conv_atted_sum],dim=1)\n",
    "        \n",
    "        out_feature =  F.relu(self.last_layer(catted))\n",
    "        \n",
    "        if self.is_train:\n",
    "            bin_class = self.train_layer(out_feature)\n",
    "            return bin_class,new_conv_atted_sum,new_conv_atted_sum\n",
    "        return out_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/gauthier/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "e = SpatialAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 49])\n",
      "torch.Size([1, 1, 49])\n",
      "torch.Size([1, 49])\n",
      "tensor([[20321.7949, 18147.2051, 18455.6406, 13869.2510,  4315.6860,  6013.4707,\n",
      "          6439.5020, 19580.2598, 18510.7715, 21936.9277, 20676.4414,  6510.4326,\n",
      "          6808.3188,  7364.6782, 23788.3262, 23139.1699, 23391.9707, 24493.1055,\n",
      "         14593.8633,  9144.5596,  8480.2109, 19389.6621, 19129.3008, 17385.1699,\n",
      "         17292.3340, 13165.7002,  7942.8003,  7376.9873, 15499.4795, 10211.5156,\n",
      "          8024.8042,  7639.8252, 10640.0000, 10206.1104, 13503.0732, 18574.6523,\n",
      "         13842.2520, 10002.1230,  6917.8418, 13336.1738, 14061.9150, 20125.8945,\n",
      "         14981.3018, 11414.4121,  9760.4688,  6178.6562, 13524.9785, 15691.7314,\n",
      "         20648.0879]], grad_fn=<ViewBackward>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([1, 49])\n",
      "torch.Size([1, 49, 2048])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-38e311147eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mot/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-2976ba6c77d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, old_feature, new_feature)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_conv_atted_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mold_conv_atted_sum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "e(input_batch,input_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
